cluster.hiveserver=gateway1.cluster

app.name=${project.artifactId}
app.host=gateway1.cluster
app.home=${app.user.home}/${project.build.finalName}
app.user.name=${project.artifactId}
app.user.password=Bdpp1234!
app.user.home=/home/${app.user.name}
app.hdfs.user.name=bdp-dwh
app.hdfs.user.home=hdfs:///user/${app.hdfs.user.name}

# Spark设置
spark.num.executors=3
spark.executor.cores=3
spark.executor.memory=1024m

# bdp_metric jdbc configs
# 此处的数据库主机不要使用balancer1.cluster, 因为运行MR作业的节点是3个worker节点,也就是在均衡中配置的三个节点
# 而阿里云的四层负载均衡服务不支持负载均衡后端ECS实例作为客户端直接访问负载均衡，所以如果使用balancer1.cluster作为地址会经常连接数据库失败
bdp.metric.db.host=master1.cluster
bdp.metric.jdbc.url=jdbc:mysql://${bdp.metric.db.host}/bdp_metric?useSSL=false&useUnicode=true&characterEncoding=utf-8&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=GMT
bdp.metric.jdbc.user=bdp_metric
bdp.metric.jdbc.password=Bdpp1234!

# bdp_master jdbc configs
# 此处的数据库主机不要使用balancer1.cluster, 因为运行MR作业的节点是3个worker节点,也就是在均衡中配置的三个节点
# 而阿里云的四层负载均衡服务不支持负载均衡后端ECS实例作为客户端直接访问负载均衡，所以如果使用balancer1.cluster作为地址会经常连接数据库失败
bdp.master.db.host=master1.cluster
bdp.master.jdbc.url=jdbc:mysql://${bdp.master.db.host}/bdp_master?useSSL=false&useUnicode=true&characterEncoding=utf-8&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=GMT
bdp.master.jdbc.user=bdp_master
bdp.master.jdbc.password=Bdpp1234!