cluster.hiveserver=192.168.170.129

app.name=${project.artifactId}
app.host=192.168.170.129
app.home=${app.user.home}/${project.build.finalName}
app.user.name=root
app.user.password=15931596981
app.user.home=/home/${app.user.name}
app.hdfs.user.name=root
app.hdfs.user.home=hdfs:///user/${app.hdfs.user.name}

# Spark设置
spark.num.executors=1
spark.executor.cores=1
spark.executor.memory=1024m

# bdp_metric jdbc configs
# 此处的数据库主机不要使用balancer1.cluster, 因为运行MR作业的节点是3个worker节点,也就是在均衡中配置的三个节点
# 而阿里云的四层负载均衡服务不支持负载均衡后端ECS实例作为客户端直接访问负载均衡，所以如果使用balancer1.cluster作为地址会经常连接数据库失败
bdp.metric.db.host=192.168.170.1
bdp.metric.jdbc.url=jdbc:mysql://${bdp.metric.db.host}/bdp_metric?useSSL=false&useUnicode=true&characterEncoding=utf-8&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=GMT&zeroDateTimeBehavior=CONVERT_TO_NULL
bdp.metric.jdbc.user=root
bdp.metric.jdbc.password=root

# bdp_master jdbc configs
# 此处的数据库主机不要使用balancer1.cluster, 因为运行MR作业的节点是3个worker节点,也就是在均衡中配置的三个节点
# 而阿里云的四层负载均衡服务不支持负载均衡后端ECS实例作为客户端直接访问负载均衡，所以如果使用balancer1.cluster作为地址会经常连接数据库失败
bdp.master.db.host=192.168.170.1
bdp.master.jdbc.url=jdbc:mysql://${bdp.master.db.host}/bdp_master?useSSL=false&useUnicode=true&characterEncoding=utf-8&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=GMT&zeroDateTimeBehavior=CONVERT_TO_NULL
bdp.master.jdbc.user=root
bdp.master.jdbc.password=root